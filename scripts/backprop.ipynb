{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "3.7.5 (default, Oct 25 2019, 15:51:11) \n[GCC 7.3.0]\n"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Import PyTorch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.autograd import Function # import Function to create custom activations\n",
    "from torch.nn.parameter import Parameter # import Parameter to create custom activations with learnable parameters\n",
    "from torch import optim # import optimizers for demonstrations\n",
    "import torch.nn.functional as F # import torch functions\n",
    "from torchvision import datasets, transforms # import transformations to use for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = 0.2\n",
    "a = 5\n",
    "b = 2\n",
    "e = 0.001\n",
    "robot_speed = 0.1\n",
    "robot_pose = torch.tensor([1.,2.01],requires_grad=True)\n",
    "goal= torch.tensor([10.,20.],requires_grad=True)\n",
    "init_pose = torch.tensor([0.,1.],requires_grad=True)\n",
    "agents_pose = torch.tensor([[1.,3.],[5.,2.],[1.,0.]],requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HSFM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tensor_inf_to_zero(bad_tensor):\n",
    "    bad_tensor[bad_tensor == float('inf')] = 0\n",
    "    bad_tensor.requires_grad_(True)\n",
    "    bad_tensor.retain_grad()\n",
    "    return bad_tensor\n",
    "\n",
    "def calc_forces(state):\n",
    "    rep_force = 10 * calc_rep_forces(state)\n",
    "    attr_force = calc_attractive_forces(state)\n",
    "    return rep_force + attr_force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rep_forces(state):\n",
    "    # state = state_[:,0:2]\n",
    "    aux1 = torch.tensor(([1.,0.],[0.,1.])) # used to transform state from [N_rows*2] to [N_rows*(2*N_rows)]\n",
    "    for i in range(0,state.shape[0]-1):\n",
    "        aux1 = torch.cat((aux1,torch.tensor(([1.,0.],[0.,1.]))),dim=1)\n",
    "    aux1.requires_grad_(True)\n",
    "    aux1.retain_grad()\n",
    "    '''\n",
    "        e.g. : state   [[1,  0]\n",
    "                        [2,  1]\n",
    "                        [-1,-1]\n",
    "                        [0, -1]]\n",
    "        new state_concated:         \n",
    "                       [[1,  0, 1,  0, 1,  0, 1,  0]\n",
    "                        [2,  1, 2,  1, 2,  1, 2,  1]\n",
    "                        [-1,-1, -1,-1, -1,-1, -1,-1]\n",
    "                        [0, -1, 0, -1, 0, -1, 0, -1]]\n",
    "    '''\n",
    "    \n",
    "    state_concated = state.clone().matmul(aux1.clone()).requires_grad_(True)\n",
    "    state_concated.retain_grad()\n",
    "    # print (\"state \", state)\n",
    "    state_concated_t = state.reshape(1,-1).requires_grad_(True)\n",
    "    for i in range(0,state.shape[0]-1):\n",
    "        state_concated_t = torch.cat([state_concated_t,state.reshape(1,-1)]).requires_grad_(True)\n",
    "        \n",
    "        '''    state_concated_t tensor(\n",
    "        [[ 1.,  0.,  2.,  1., -1., -1.,  0., -1.],\n",
    "         [ 1.,  0.,  2.,  1., -1., -1.,  0., -1.],\n",
    "         [ 1.,  0.,  2.,  1., -1., -1.,  0., -1.],\n",
    "         [ 1.,  0.,  2.,  1., -1., -1.,  0., -1.]]\n",
    "        '''\n",
    "    state_concated_t.requires_grad_(True)\n",
    "    delta_pose = (state_concated_t - state_concated).requires_grad_(True)\n",
    "    delta_pose.retain_grad()\n",
    "    auxullary = torch.zeros(state_concated.shape[0], state_concated.shape[1])\n",
    "    auxullary.retain_grad()\n",
    "    for i in range(state_concated.shape[0]):\n",
    "        auxullary[i,2*i] = 1.\n",
    "        auxullary[i,2*i+1] = 1.\n",
    "\n",
    "    ''' used to calc x+y of each agent pose\n",
    "        auxullary  tensor([\n",
    "            [1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "            [0., 0., 1., 1., 0., 0., 0., 0.],\n",
    "            [0., 0., 0., 0., 1., 1., 0., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 1., 1.]])\n",
    "    '''\n",
    "    dist_squared = ((delta_pose)**2).requires_grad_(True)\n",
    "    dist_squared.retain_grad()\n",
    "    # used to calc delta_x**2 +delta_y**2 of each agent\n",
    "    aux = auxullary.t()\n",
    "    aux.retain_grad()\n",
    "    # sqrt(delta_x**2 +delta_y**2) -> distance\n",
    "    dist_squared += 0.0000001 # TODO: otherwise  when doing backprop: sqrt(0)' -> nan\n",
    "    dist = (dist_squared.matmul(aux)).requires_grad_(True) ## aka distance\n",
    "    dist = torch.sqrt(dist) + 10000*torch.eye(dist.shape[0])  #TODO: deal with 1/0,\n",
    "    A = 2 * (10**3) # const param from  formula(21) from `When Helbing Meets Laumond: The Headed Social Force Model`\n",
    "    force_amplitude = A * torch.exp((0.3 -dist)/0.08).requires_grad_(True) ## according to Headed Social Force Model\n",
    "    force = force_amplitude.matmul(delta_pose/(dist+0.00001).matmul(auxullary)) # formula(21) from `When Helbing Meets Laumond: The Headed Social Force Model`\n",
    "    force.requires_grad_(True)\n",
    "    force.retain_grad()    \n",
    "    aux2 = aux1.clone().t()\n",
    "    force = force.matmul(aux2).requires_grad_(True)\n",
    "    return force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_attractive_forces(input):\n",
    "    global goals\n",
    "    delta_pose = goals -input\n",
    "    # print (\"delta_pose \", delta_pose)\n",
    "    dist = torch.sqrt( delta_pose[:,0:1]**2 + delta_pose[:,1:2]**2)\n",
    "    force = delta_pose/torch.cat((dist,dist),dim=1)\n",
    "    return force "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backprop Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cost_function(a=a, b=b,e=e,robot_speed=robot_speed, robot_pose=robot_pose,goal=goal,init_pose=init_pose,agents_pose=agents_pose ):\n",
    "    costs = torch.zeros(agents_pose.shape,requires_grad=False)\n",
    "    costs.retain_grad()\n",
    "    PG = (robot_pose - init_pose)*(-init_pose+goal)/torch.norm(-init_pose+goal)\n",
    "    PG.retain_grad()\n",
    "    # Blame\n",
    "    B = torch.zeros(len(agents_pose),requires_grad=False)\n",
    "    B.retain_grad()\n",
    "    if robot_speed>e:\n",
    "        for n in range(len(agents_pose)):\n",
    "            # TODO: go into matrix math\n",
    "            B[n] = torch.exp(-torch.norm(agents_pose[n]-robot_pose)/b)\n",
    "    # Cost\n",
    "    for n in range(len(B)):\n",
    "        costs[n] = -a*PG+B[n]\n",
    "    return costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_speed(input_state, limit):\n",
    "\n",
    "    ampl = torch.sqrt(input_state[:,0:1]**2 + input_state[:,1:2]**2)\n",
    "    \n",
    "    mask=torch.cat((ampl>limit,ampl>limit),dim=1)\n",
    "    ampl_2D = torch.cat((ampl,ampl),dim=1)\n",
    "    # print (mask)\n",
    "    # print (input_state[mask])\n",
    "    # print (ampl_2D[ampl_2D>3])\n",
    "    input_state[mask] = input_state[mask].clone() * limit /ampl_2D[mask]\n",
    "    return input_state\n",
    "\n",
    "def calc_new_vel(input_state, forces):\n",
    "    # input_vel = input_state[:,2:4].view(-1,2)\n",
    "    input_state[:,2:4] = (forces * DT / 6.0 )+ input_state[:,2:4]\n",
    "    # limit max speed : \n",
    "    # input_state[:,2:3]**2 + input_state[:,3:4]**2\n",
    "    # input_state[:,2:4] = limit_speed(input_state[:,2:4], 0.2)\n",
    "    return input_state\n",
    "\n",
    "def calc_new_pose(input):\n",
    "    input[:,0:2] = input[:,0:2] + input[:,2:4] * DT\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test : usage without using nn.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n  ---goals: \n tensor([[0.4518, 0.5772],\n        [0.3859, 0.6346],\n        [0.2434, 0.0356],\n        [0.7530, 0.2302]])\n\n  ---final: \n tensor([[ 5.7659,  2.4618,  8.5777,  8.9635],\n        [ 1.6402,  2.0705,  0.9360,  8.3520],\n        [10.0345,  2.0701,  7.0611,  3.3246],\n        [ 2.9619,  9.8199,  4.8139,  8.8295]], grad_fn=<CopySlices>)\n\n  ---final delta: \n tensor([[5.3141, 1.8846],\n        [1.2543, 1.4359],\n        [9.7911, 2.0345],\n        [2.2089, 9.5897]], grad_fn=<SubBackward0>)\nfinal cost tensor([[-2.2374, -4.3775],\n        [-1.6037, -3.7438],\n        [-2.3178, -4.4579],\n        [-2.3109, -4.4510]], grad_fn=<AddBackward0>)\nNone\n"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "na = numb_agent = 4\n",
    "\n",
    "# data = torch.tensor(([0.1, 2, 0., 0], [-5, -5, 0., 0], [-5, 0, 0., 0], [0, -5, 0., 0]),requires_grad=False)\n",
    "# goals = torch.tensor(([-5, -5.], [-0,-0], [-0,-5], [-5, -0]),requires_grad=True)\n",
    "data = torch.rand((na,4))\n",
    "data = 10 * data.clone().requires_grad_(True)\n",
    "goals =torch.rand((na,2),requires_grad=False)\n",
    "goals\n",
    "cost = torch.zeros(na,2)\n",
    "\n",
    "\n",
    "# arrays for plotting\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "x2 = []\n",
    "y2 = []\n",
    "x3 = []\n",
    "y3 = []\n",
    "x4 = []\n",
    "y4 = []\n",
    "t = 0\n",
    "\n",
    "for i in range(0,1):\n",
    "\n",
    "    # forces, _ = l((data,cost))\n",
    "    forces = calc_forces(data[:,0:2])\n",
    "    data = calc_new_vel(data, forces)\n",
    "    # print (data.shape)\n",
    "    data = calc_new_pose(data)\n",
    "    cost+=calc_cost_function(agents_pose=data[:,0:2])\n",
    "    # print (data.shape)\n",
    "    # print (forces.shape)\n",
    "    \n",
    "    data = calc_new_vel(data, forces)\n",
    "    x.append(data.data[0,0].item())\n",
    "    y.append(data.data[0,1].item())\n",
    "    x2.append(data.data[1,0].item())\n",
    "    y2.append(data.data[1,1].item())\n",
    "    x3.append(data.data[2,0].item())\n",
    "    y3.append(data.data[2,1].item())\n",
    "    x4.append(data.data[3,0].item())\n",
    "    y4.append(data.data[3,1].item())\n",
    "    z.append(t)\n",
    "    t+=DT\n",
    "    # if i % 10 ==0:\n",
    "    #     print (\"\\n  ---interm: \\n\",data)\n",
    "        \n",
    "\n",
    "print (\"\\n  ---goals: \\n\",goals)\n",
    "\n",
    "print (\"\\n  ---final: \\n\",data)\n",
    "\n",
    "print (\"\\n  ---final delta: \\n\",data[:,0:2] - goals)\n",
    "\n",
    "print (\"final cost\", cost)\n",
    "cost.backward(data[:,0:2])\n",
    "print (data.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot(x,  y,   z,'ro',linewidth=1)\n",
    "ax.plot(x2, y2, z,'ro',color='skyblue')\n",
    "ax.plot(x3, y3, z,'ro',color='olive')\n",
    "ax.plot(x4, y4, z,'ro',color='yellow')\n",
    "ax.set(zlabel='time (s)', ylabel='y', xlabel = \"x\",\n",
    "       title='traj of persons')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((2,2)).requires_grad_(True)\n",
    "b = torch.ones((2,2))\n",
    "a = a.matmul(b)\n",
    "a.backward(torch.ones((2,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bonsai",
   "language": "python",
   "name": "bonsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}